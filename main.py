from uspto_patent_data_parser import uspto
from tqdm import tqdm
import lm_dataformat as lmd

# Base URL for USPTO Patent rants
BASE_URL = 'https://bulkdata.uspto.gov/data/patent/grant/redbook/fulltext/'

METADATA_CATEGORIES = ['INVT', 'ASSG', 'CLAS', 'URL', 'ABST']

def extract_pre_2002(archive):
  for year in range(1976, 2002):
    print(f"Extracting patents from {year}")
    # Filtering is needed because some pre-2002 pages have multiple formats. This selects for just APS files.
    file_list = list(filter(lambda x: x.startswith('pftaps'), uspto.get_patent_files_by_year(year)))
    for filename in tqdm(file_list):
      file_url = BASE_URL + str(year) + '/' + filename
      # UREF is the citation section prior to 2002.
      # The background section is in BSUM before 2005.
      categories = METADATA_CATEGORIES + ['UREF'] + ['BSUM']
      try:
        data = uspto.read_and_parse_from_url(file_url, categories)
      except KeyError:
        # The first file from 1980 throws a KeyError
        continue
      for datum in data:
        metadata = { key: datum[key] for key in datum if key != 'breif_summary' }
        text_list = None
        if 'breif_summary' not in datum:
          continue
        # Pre-2002, the background section is within the "breif summary" (sic) section
        # which is arranged as a series of key value pairs, where the keys are a mix of
        # header (PAC*) and paragraph (PAL*) tags, and the values are the text contents.
        # We first locate the start of the background section by finding the appropriate
        # PAC* tag, and then find the next PAC* tag after it, to compute the paragraph
        # boundaries of the section, and extract from within those bounds.
        section = datum['breif_summary']
        titles = [(idx, tag) for (idx, tag) in enumerate(section.keys()) if 'PAC' in tag]
        background_start_indices = [idx for (idx, tag) in titles if 'BACKGROUND' in section[tag]]
        if len(background_start_indices) > 0:
          background_start_index = background_start_indices[0] + 1
        else:
          # Document has no identifiable background section
          continue
        # Grab index of the first section after the background
        background_end_indices = [idx for (idx, tag) in titles if idx > background_start_index]
        if len(background_end_indices) > 0:
          background_end_index = background_end_indices[0]
        else:
          # Background is the last header
          background_end_index = len(section.keys())
        text_list = list(section.values())[background_start_index:background_end_index]

        # Occasionally, you'll come across empty sections.
        if len(text_list) > 0:
          text = '\n'.join(text_list)
          archive.add_data(text, meta=metadata)
    archive.commit(archive_name=str(year))
  return archive

def extract_2002_to_2004(archive):
  for year in range(2002, 2005):
    print(f"Extracting patents from {year}")
    file_list = uspto.get_patent_files_by_year(year)
    for filename in tqdm(file_list):
      file_url = BASE_URL + str(year) + '/' + filename
      # CITA is the citation section since 2002.
      # The background section is in BSUM before 2005.
      categories = METADATA_CATEGORIES + ['CITA'] + ['BSUM']
      data = uspto.read_and_parse_from_url(file_url, categories)
      for datum in data:
        metadata = { key: datum[key] for key in datum if key != 'brief_summary' }
        text_list = None
        if 'brief_summary' not in datum:
          continue
        text_list = datum['brief_summary']
  
        # Occasionally, you'll come across empty sections.
        if len(text_list) > 0:
          text = '\n'.join(text_list)
          archive.add_data(text, meta=metadata)
    archive.commit(archive_name=str(year))
  return archive

def extract_post_2004(archive):
  for year in range(2005, 2020 + 1):
    print(f"Extracting patents from {year}")
    file_list = uspto.get_patent_files_by_year(year)
    for filename in tqdm(file_list):
      file_url = BASE_URL + str(year) + '/' + filename
      # CITA is the citation section since 2002.
      # The background section is in DETD since 2005.
      categories = METADATA_CATEGORIES + ['CITA'] + ['DETD']
      try:
        data = uspto.read_and_parse_from_url(file_url, categories)
      except AttributeError:
        # Document from 2005 raises an AttributeError
        continue
      for datum in data:
        metadata = { key: datum[key] for key in datum if key != 'detailed_description' }
        # International classifications sometimes lead to ValueErrors otherwise
        if 'classifications' in metadata:
          classifications = metadata['classifications']
          classifications.pop('classifications_ipcr_list', None)
          metadata['classifications'] = classifications
        text_list = None
        if 'detailed_description' not in datum:
          continue
        section = datum['detailed_description']
        # List out the sub-headings within the detailed description.
        subheadings = list(section.keys())

        # Background section may have a variable name
        background_headings = [tag for tag in subheadings if tag and 'BACKGROUND' in tag]

        if len(background_headings) < 1:
          continue
        else:
          background_heading = background_headings[0]
          text_list = section[background_heading]

        # Occasionally, you'll come across empty sections.
        if len(text_list) > 0:
          text = '\n'.join(text_list)
          archive.add_data(text, meta=metadata)
    archive.commit(archive_name=str(year))
  return archive

archive = lmd.Archive('out')
archive = extract_pre_2002(archive)
archive = extract_2002_to_2004(archive)
archive = extract_post_2004(archive)
